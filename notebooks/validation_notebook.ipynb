{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "# Get python version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[39;1mVirtualenv\u001b[39;22m\n",
      "\u001b[34mPython\u001b[39m:         \u001b[32m3.10.12\u001b[39m\n",
      "\u001b[34mImplementation\u001b[39m: \u001b[32mCPython\u001b[39m\n",
      "\u001b[34mPath\u001b[39m:           \u001b[32m/workspaces/template-python-project/.venv\u001b[39m\n",
      "\u001b[34mExecutable\u001b[39m:     \u001b[32m/workspaces/template-python-project/.venv/bin/python\u001b[39m\n",
      "\u001b[34mValid\u001b[39m:          \u001b[32mTrue\u001b[39m\n",
      "\n",
      "\u001b[39;1mSystem\u001b[39;22m\n",
      "\u001b[34mPlatform\u001b[39m:   \u001b[32mlinux\u001b[39m\n",
      "\u001b[34mOS\u001b[39m:         \u001b[32mposix\u001b[39m\n",
      "\u001b[34mPython\u001b[39m:     \u001b[32m3.10.12\u001b[39m\n",
      "\u001b[34mPath\u001b[39m:       \u001b[32m/usr\u001b[39m\n",
      "\u001b[34mExecutable\u001b[39m: \u001b[32m/usr/bin/python3.10\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# check if in poetry environment\n",
    "!poetry env info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 15:23:58.056511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-07 15:23:58.895436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n",
      "Name: /physical_device:GPU:1   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  7 15:24:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 30%   38C    P8    16W / 230W |  11751MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   42C    P8    24W / 230W |   1418MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    199257      C                                    6520MiB |\n",
      "|    0   N/A  N/A   1566353      C                                     891MiB |\n",
      "|    0   N/A  N/A   1896445      C                                    1393MiB |\n",
      "|    0   N/A  N/A   2398646      C                                    2181MiB |\n",
      "|    0   N/A  N/A   4063711      C                                     763MiB |\n",
      "|    1   N/A  N/A   1896445      C                                    1415MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn: /usr/include/cudnn.h\n"
     ]
    }
   ],
   "source": [
    "# cudnn validation\n",
    "!whereis cudnn.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
